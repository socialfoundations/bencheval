Rank
Model

Model Size (GB)
Embedding Dimensions
Max Tokens
Average (56 datasets)
Classification Average (12 datasets)
Clustering Average (11 datasets)
Pair Classification Average (3 datasets)
Reranking Average (4 datasets)
Retrieval Average (15 datasets)
STS Average (10 datasets)
Summarization Average (1 dataset)
1
SFR-Embedding-Mistral

14.22
4096
32768
67.56
78.33
51.67
88.54
60.64
59
85.05
31.16
2
voyage-lite-02-instruct


1024
4000
67.13
79.25
52.42
86.87
58.24
56.6
85.79
31.01
3
e5-mistral-7b-instruct

14.22
4096
32768
66.63
78.47
50.26
88.34
60.21
56.89
84.63
31.4
4
UAE-Large-V1

1.34
1024
512
64.64
75.58
46.73
87.25
59.88
54.66
84.54
32.03
5
text-embedding-3-large


3072
8191
64.59
75.45
49.01
85.72
59.16
55.44
81.73
29.92
6
voyage-lite-01-instruct


1024
4000
64.49
74.79
47.4
86.57
59.74
55.58
82.93
30.97
7
Cohere-embed-english-v3.0


1024
512
64.47
76.49
47.43
85.84
58.01
55
82.62
30.18
8
bge-large-en-v1.5

1.34
1024
512
64.23
75.97
46.08
87.12
60.03
54.29
83.11
31.61
9
Cohere-embed-multilingual-v3.0


1024
512
64.01
76.01
46.6
86.15
57.86
53.84
83.15
30.99
10
GIST-Embedding-v0

0.44
768
512
63.71
76.03
46.21
86.32
59.37
52.31
83.51
30.87
11
bge-base-en-v1.5

0.44
768
512
63.55
75.53
45.77
86.55
58.86
53.25
82.4
31.07
12
ember-v1

1.34
1024
512
63.54
75.99
45.58
87.37
60.04
51.92
83.34
30.82
13
sf_model_e5

1.34
1024
512
63.34
73.96
46.61
86.85
59.86
51.8
83.85
31.61
14
gte-large

0.67
1024
512
63.13
73.33
46.84
85
59.13
52.22
83.35
31.66
15
stella-base-en-v2

0.22
768
512
62.61
75.28
44.9
86.45
58.78
50.1
83.02
32.52
16
gte-base

0.22
768
512
62.39
73.01
46.2
84.57
58.61
51.14
82.3
31.17
17
text-embedding-3-small


1536
8191
62.26
73.21
46.65
85.04
56.72
51.08
81.58
31.12
18
e5-large-v2

1.34
1024
512
62.25
75.24
44.49
86.03
56.61
50.56
82.05
30.19
19
bge-small-en-v1.5

0.13
384
512
62.17
74.14
43.82
84.92
58.36
51.68
81.59
30.12
20
Cohere-embed-english-light-v3.0


384
512
62.01
74.31
44.64
85.05
56.09
51.34
80.92
31.29
21
text-embedding-3-large-256


256
8191
62
71.97
46.23
84.22
57.99
51.66
81.04
29.92
22
instructor-xl

4.96
768
512
61.79
73.12
44.74
86.62
57.29
49.26
83.06
32.32
23
instructor-large

1.34
768
512
61.59
73.86
45.29
85.89
57.54
47.57
83.15
31.84
24
e5-base-v2

0.44
768
512
61.5
73.84
43.8
85.73
55.91
50.29
81.05
30.28
25
multilingual-e5-large

2.24
1024
514
61.5
74.81
41.06
84.75
55.86
51.43
81.56
29.69
26
e5-large

1.34
1024
512
61.42
73.14
43.33
85.94
56.53
49.99
82.06
30.97
27
gte-small

0.07
384
512
61.36
72.31
44.89
83.54
57.7
49.46
82.07
30.42
28
text-embedding-ada-002


1536
8191
60.99
70.93
45.9
84.89
56.32
49.25
80.97
30.8
29
udever-bloom-7b1

28.28
4096
2048
60.63
72.13
40.81
85.4
55.91
49.34
83.01
30.97
30
e5-base

0.44
768
512
60.44
72.63
42.11
85.09
55.7
48.75
80.96
31.01
31
jina-embeddings-v2-base-en




60.38
73.45
41.73
85.38
56.98
47.87
80.7
31.6
32
Cohere-embed-multilingual-light-v3.0


384
512
60.08
70.57
41.98
83.95
55.06
50.15
80.09
30.41
33
e5-small-v2

0.13
384
512
59.93
72.94
39.92
84.67
54.32
49.04
80.39
31.16
34
udever-bloom-3b

12.01
2560
2048
59.86
71.91
40.74
84.06
54.9
47.67
82.37
30.62
35
instructor-base

0.44
768
512
59.54
72.36
41.9
83.51
56.2
45.12
82.29
29.85
36
sentence-t5-xxl

9.73
768
512
59.51
73.42
43.72
85.06
56.42
42.24
82.63
30.08
37
multilingual-e5-base

1.11
768
514
59.45
73.02
37.89
83.57
54.84
48.88
80.26
30.11
38
XLM-3B5-embedding




59.29
72.25
43.48
79.23
57.12
44.99
80.47
29.02
39
gtr-t5-xxl

9.73
768
512
58.97
67.41
42.42
86.12
56.66
48.48
78.38
30.64
40
SGPT-5.8B-weightedmean-msmarco-specb-bitfit

23.5
4096
2048
58.93
68.13
40.34
82
56.56
50.25
78.1
31.46
41
e5-small

0.13
384
512
58.89
71.67
39.51
85.08
54.45
46.01
80.87
31.39
42
gte-tiny

0.05
384
512
58.69
70.35
42.09
82.83
55.77
44.92
80.46
29.47
43
gtr-t5-xl

2.48
768
512
58.42
67.11
41.51
86.13
55.96
47.96
77.8
30.21
44
udever-bloom-1b1

4.26
1536
2048
58.29
70.17
39.11
83.11
54.28
45.27
81.52
31.1
45
gtr-t5-large

0.67
768
512
58.28
67.14
41.6
85.32
55.36
47.42
78.19
29.5
46
jina-embeddings-v2-small-en




58
68.82
40.08
84.44
55.09
45.14
80
30.56
47
XLM-0B6-embedding




57.97
70.55
42.97
77.83
55.6
43.39
79.02
30.25
48
multilingual-e5-small

0.47
384
512
57.87
70.74
37.08
82.59
53.87
46.64
79.1
29.98
49
sentence-t5-xl

2.48
768
512
57.87
72.84
42.34
86.06
54.71
38.47
81.66
29.91
50
all-mpnet-base-v2

0.44
768
514
57.78
65.07
43.69
83.04
59.36
43.81
80.28
27.49
51
sgpt-bloom-7b1-msmarco

28.27
4096
2048
57.59
66.19
38.93
81.9
55.65
48.22
77.74
33.6
52
jina-embedding-l-en-v1

1.34
1024
512
57.38
67.76
37.15
84.8
56.42
44.81
80.96
29.85
53
SGPT-2.7B-weightedmean-msmarco-specb-bitfit

10.74
2560
2048
57.17
67.13
39.83
80.65
54.67
46.54
76.83
31.03
54
sentence-t5-large

0.67
768
512
57.06
72.31
41.65
84.97
54
36.71
81.83
29.64
55
MegatronBert-1B3-embedding




56.81
69.65
40.86
76.9
55.5
41.41
79.11
31.01
56
bge-micro-v2

0.03
384
512
56.57
68.04
39.18
82.81
54.29
42.56
78.65
29.87
57
all-MiniLM-L12-v2

0.13
384
512
56.53
63.21
41.81
82.41
58.44
42.69
79.8
27.9
58
all-MiniLM-L6-v2

0.09
384
512
56.26
63.05
42.35
82.37
58.04
41.95
78.9
30.81
59
jina-embedding-b-en-v1

0.44
768
512
56.26
66.07
35.88
83.04
55.84
44.03
79.93
30.71
60
SGPT-1.3B-weightedmean-msmarco-specb-bitfit

5.36
2048
2048
56.2
66.52
39.92
79.58
54
44.49
75.74
30.43
61
gtr-t5-base

0.22
768
512
56.19
65.25
38.63
83.85
54.23
44.67
77.07
29.67
62
contriever-base-msmarco

0.44
768
512
56
66.68
41.1
82.54
53.14
41.88
76.51
30.36
63
udever-bloom-560m

2.24
1024
2048
55.81
68.04
36.89
81.05
52.6
41.19
79.93
32.06
64
bge-micro

0.03
384
512
55.71
66.35
39.46
81.77
54.28
40.82
78.37
31.16
65
sentence-t5-base

0.22
768
512
55.27
69.81
40.21
85.18
53.09
33.63
81.14
31.39
66
bge-small-4096

0.14
384
4096
54.42
67.8
38.03
81.4
53.64
36.08
78.59
29.83
67
lodestone-base-4096-v1

0.27
768
4096
54.24
67.3
40.9
80.4
53.95
36.99
73.7
31.23
68
SGPT-5.8B-weightedmean-nli-bitfit

23.5
4096
2048
53.74
70.14
36.98
77.03
52.33
32.34
80.53
30.38
69
multi-qa-MiniLM-L6-cos-v1


384
512
53.29
61.67
35.67
80.86
54.58
41.17
74.23
31.05
70
msmarco-bert-co-condensor

0.44
768
512
52.35
64.71
37.64
81.74
51.84
32.96
76.47
29.5
71
jina-embedding-s-en-v1

0.14
512
512
52.33
60.56
32.56
79.22
53.07
38.91
78.06
31.25
72
SGPT-125M-weightedmean-msmarco-specb-bitfit

0.55
768
2048
51.25
60.72
35.79
75.23
50.58
37.04
73.41
29.71
73
text-similarity-ada-001


1024
2046
49.52
70.44
37.52
76.86
49.02
18.36
78.6
26.94
74
sup-simcse-bert-base-uncased

0.44
768
512
48.87
67.32
33.43
73.68
47.54
21.82
79.12
31.17
75
SGPT-125M-weightedmean-nli-bitfit

0.55
768
2048
45.97
61.46
30.95
71.78
47.56
20.9
74.71
30.26
76
unsup-simcse-bert-base-uncased

0.44
768
512
45.45
62.5
29.04
70.33
46.47
20.29
74.33
31.15
77
LaBSE

1.88
768
512
45.21
62.71
29.55
78.87
48.42
18.99
70.8
31.05
78
komninos

0.27
300
N/A
42.06
57.65
26.57
72.94
44.75
21.22
62.46
30.49
79
glove.6B.300d

0.48
300
N/A
41.96
57.29
27.73
70.92
43.29
21.62
61.85
28.87
80
SONAR




40.72
60.43
22.9
71.4
46.18
13.47
67.18
30.56
81
allenai-specter

0.44
768
512
40.28
52.37
34.06
61.37
48.1
15.88
61.02
27.66
82
bert-base-uncased

0.44
768
512
38.33
61.66
30.12
56.33
43.44
10.59
54.36
29.82
83
LASER2

0.17
1024
N/A
34.95
53.18
15.28
68.86
41.44
7.94
63.27
26.8
